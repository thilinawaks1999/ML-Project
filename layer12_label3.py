{"metadata": {"kernelspec": {"language": "python", "display_name": "Python 3", "name": "python3"}, "language_info": {"pygments_lexer": "ipython3", "nbconvert_exporter": "python", "version": "3.6.4", "file_extension": ".py", "codemirror_mode": {"name": "ipython", "version": 3}, "name": "python", "mimetype": "text/x-python"}}, "nbformat_minor": 4, "nbformat": 4, "cells": [{"cell_type": "code", "source": "# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:12.744873Z\",\"iopub.execute_input\":\"2023-09-24T09:47:12.745211Z\",\"iopub.status.idle\":\"2023-09-24T09:47:13.087676Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:12.745185Z\",\"shell.execute_reply\":\"2023-09-24T09:47:13.086036Z\"}}\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:13.090712Z\",\"iopub.execute_input\":\"2023-09-24T09:47:13.093326Z\",\"iopub.status.idle\":\"2023-09-24T09:47:15.520099Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:13.093282Z\",\"shell.execute_reply\":\"2023-09-24T09:47:15.518097Z\"}}\nimport pandas as pd\nimport numpy as np\nfrom pandas import Series\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import f1_score\nimport seaborn as sns\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:15.521643Z\",\"iopub.execute_input\":\"2023-09-24T09:47:15.522062Z\",\"iopub.status.idle\":\"2023-09-24T09:47:23.608638Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:15.522027Z\",\"shell.execute_reply\":\"2023-09-24T09:47:23.607914Z\"}}\ntrain_df = pd.read_csv('/kaggle/input/layer12/train.csv')\nvalid_df = pd.read_csv('/kaggle/input/layer12/valid.csv')\ntest_df = pd.read_csv('/kaggle/input/layer12/test.csv')\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:23.611090Z\",\"iopub.execute_input\":\"2023-09-24T09:47:23.611455Z\",\"iopub.status.idle\":\"2023-09-24T09:47:23.621021Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:23.611427Z\",\"shell.execute_reply\":\"2023-09-24T09:47:23.619619Z\"}}\ntrain_df.shape\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:23.622352Z\",\"iopub.execute_input\":\"2023-09-24T09:47:23.622666Z\",\"iopub.status.idle\":\"2023-09-24T09:47:23.663966Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:23.622642Z\",\"shell.execute_reply\":\"2023-09-24T09:47:23.663258Z\"}}\ntrain_df.head()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:23.665036Z\",\"iopub.execute_input\":\"2023-09-24T09:47:23.665413Z\",\"iopub.status.idle\":\"2023-09-24T09:47:23.691899Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:23.665390Z\",\"shell.execute_reply\":\"2023-09-24T09:47:23.690411Z\"}}\nmissing_columns = train_df.columns[train_df.isnull().any()]\nmissing_counts = train_df[missing_columns].isnull().sum()\n\nprint('Missing Columns and Counts')\nfor column in missing_columns:\n    print( str(column) +' : '+ str(missing_counts[column]))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:23.693031Z\",\"iopub.execute_input\":\"2023-09-24T09:47:23.693521Z\",\"iopub.status.idle\":\"2023-09-24T09:47:23.722540Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:23.693496Z\",\"shell.execute_reply\":\"2023-09-24T09:47:23.721252Z\"}}\ntrain_data = train_df.copy()\nvalid_data = valid_df.copy()\ntest_data = test_df.copy()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:23.724306Z\",\"iopub.execute_input\":\"2023-09-24T09:47:23.724737Z\",\"iopub.status.idle\":\"2023-09-24T09:47:25.700904Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:23.724710Z\",\"shell.execute_reply\":\"2023-09-24T09:47:25.699794Z\"}}\ntrain_df.describe()\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:25.701754Z\",\"iopub.execute_input\":\"2023-09-24T09:47:25.702025Z\",\"iopub.status.idle\":\"2023-09-24T09:47:29.665153Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:25.702003Z\",\"shell.execute_reply\":\"2023-09-24T09:47:29.663194Z\"}}\nfrom sklearn.preprocessing import RobustScaler # eliminate outliers\n\nx_train = {}\nx_valid = {}\nx_test = {}\n\ny_train = {}\ny_valid = {}\ny_test = {}\n\n#create dictionaries for each label\nfor target_label in ['label_1','label_2','label_3','label_4']:\n\n  if target_label == \"label_2\":\n    train = train_df[train_df['label_2'].notna()]\n    valid = valid_df[valid_df['label_2'].notna()]\n  else:\n    train = train_df\n    valid = valid_df\n\n  test = test_df\n\n  scaler = RobustScaler()\n\n  x_train[target_label] = pd.DataFrame(scaler.fit_transform(train.drop(['label_1','label_2','label_3','label_4'], axis=1)), columns=[f'feature_{i}' for i in range(1,769)])\n  y_train[target_label] = train[target_label]\n\n  x_valid[target_label] = pd.DataFrame(scaler.transform(valid.drop(['label_1','label_2','label_3','label_4'], axis=1)), columns=[f'feature_{i}' for i in range(1,769)])\n  y_valid  [target_label] = valid[target_label]\n\n  x_test[target_label] = pd.DataFrame(scaler.transform(test.drop([\"ID\"],axis=1)), columns=[f'feature_{i}' for i in range(1,769)])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:29.668523Z\",\"iopub.execute_input\":\"2023-09-24T09:47:29.668896Z\",\"iopub.status.idle\":\"2023-09-24T09:47:29.698519Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:29.668868Z\",\"shell.execute_reply\":\"2023-09-24T09:47:29.696959Z\"}}\nx_train_df = x_train['label_3'].copy()\ny_train_df = y_train['label_3'].copy()\n\nx_valid_df = x_valid['label_3'].copy()\ny_valid_df = y_valid['label_3'].copy()\n\nx_test_df = x_test['label_3'].copy()\n\n# %% [markdown]\n# # Cross Validation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:47:29.699833Z\",\"iopub.execute_input\":\"2023-09-24T09:47:29.700208Z\",\"iopub.status.idle\":\"2023-09-24T09:50:27.386015Z\",\"shell.execute_reply.started\":\"2023-09-24T09:47:29.700179Z\",\"shell.execute_reply\":\"2023-09-24T09:50:27.384911Z\"}}\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import cross_val_score, KFold\n\n# Perform cross-validation\nscores = cross_val_score(SVC(), x_train_df, y_train_df, cv=5, scoring='accuracy')\n\nmean_accuracy = scores.mean()\nstd_accuracy = scores.std()\n# Print the cross-validation scores\nprint('Support Vector Machines')\nprint('\\n')\nprint(\"Cross-validation scores:\", scores)\nprint(f\"Mean Accuracy: {mean_accuracy:.2f}\")\nprint(f\"Standard Deviation: {std_accuracy:.2f}\")\n\n# %% [markdown]\n# # Feature Engineering\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:50:27.387168Z\",\"iopub.execute_input\":\"2023-09-24T09:50:27.389286Z\",\"iopub.status.idle\":\"2023-09-24T09:50:30.570259Z\",\"shell.execute_reply.started\":\"2023-09-24T09:50:27.389232Z\",\"shell.execute_reply\":\"2023-09-24T09:50:30.568289Z\"}}\nfrom sklearn.decomposition import PCA\n\npca = PCA(n_components=0.975, svd_solver='full')\npca.fit(x_train_df)\nx_train_df_pca = pd.DataFrame(pca.transform(x_train_df))\nx_valid_df_pca = pd.DataFrame(pca.transform(x_valid_df))\nx_test_df_pca = pd.DataFrame(pca.transform(x_test_df))\nprint('Shape after PCA: ',x_train_df_pca.shape)\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:50:30.571367Z\",\"iopub.execute_input\":\"2023-09-24T09:50:30.571639Z\",\"iopub.status.idle\":\"2023-09-24T09:50:30.575862Z\",\"shell.execute_reply.started\":\"2023-09-24T09:50:30.571614Z\",\"shell.execute_reply\":\"2023-09-24T09:50:30.575129Z\"}}\nfrom sklearn import metrics\n\n# %% [markdown]\n# # SVM\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:50:30.577032Z\",\"iopub.execute_input\":\"2023-09-24T09:50:30.577487Z\",\"iopub.status.idle\":\"2023-09-24T09:50:39.394392Z\",\"shell.execute_reply.started\":\"2023-09-24T09:50:30.577461Z\",\"shell.execute_reply\":\"2023-09-24T09:50:39.393108Z\"}}\nfrom sklearn import svm\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nclassifier = svm.SVC(kernel='linear', C=1)\n\nclassifier.fit(x_train_df_pca, y_train_df)\n\ny_valid_pred = classifier.predict(x_valid_df_pca)\n\nprint(\"acc_score: \",metrics.accuracy_score(y_valid_df, y_valid_pred))\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T09:50:39.396051Z\",\"iopub.execute_input\":\"2023-09-24T09:50:39.396424Z\",\"iopub.status.idle\":\"2023-09-24T10:07:25.245007Z\",\"shell.execute_reply.started\":\"2023-09-24T09:50:39.396398Z\",\"shell.execute_reply\":\"2023-09-24T10:07:25.242790Z\"}}\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform, randint\nimport numpy as np\n\nparam_dist = {\n    'C': [100,10,1,0,0.1,0.01],\n    'kernel': ['rbf','linear','poly','sigmoid'],\n    'gamma': ['scale','auto'],\n    'degree': [1,2,3,4],\n    'class_weight' : ['none','balanced']\n}\n\nsvm = SVC()\n\nrandom_search = RandomizedSearchCV(\n    svm, param_distributions=param_dist, n_iter=10, cv=5, n_jobs=-1, random_state=42, scoring='accuracy'\n)\n\nrandom_search.fit(x_train_df_pca, y_train_df)\n\nbest_params = random_search.best_params_\nbest_model = random_search.best_estimator_\n\nprint(\"best parameters:\", best_params)\n\n# %% [markdown]\n# Label 1 \n# best parameters: {'kernel': 'rbf', 'gamma': 'scale', 'degree': 4, 'class_weight': 'balanced', 'C': 100}\n# \n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:07:25.247862Z\",\"iopub.execute_input\":\"2023-09-24T10:07:25.248229Z\",\"iopub.status.idle\":\"2023-09-24T10:07:40.853000Z\",\"shell.execute_reply.started\":\"2023-09-24T10:07:25.248201Z\",\"shell.execute_reply\":\"2023-09-24T10:07:40.851598Z\"}}\nfrom sklearn import svm\n\nclassifier = svm.SVC(kernel=best_params['kernel'], C=best_params['C'], gamma=best_params['gamma'], degree=best_params['degree'], class_weight=best_params['class_weight'])\n\nclassifier.fit(x_train_df_pca, y_train_df)\n\ny_valid_pred = classifier.predict(x_valid_df_pca)\n\nprint(\"acc_score: \",metrics.accuracy_score(y_valid_df, y_valid_pred))\n\ny_test_predict_after_pca = classifier.predict(x_test_df_pca)\n\n\n\n# %% [markdown]\n# # RandomForest\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:07:40.854495Z\",\"iopub.execute_input\":\"2023-09-24T10:07:40.854816Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.387295Z\",\"shell.execute_reply.started\":\"2023-09-24T10:07:40.854789Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.386209Z\"}}\nfrom sklearn.ensemble import RandomForestClassifier\n\nclassifier = RandomForestClassifier(n_estimators=100, random_state=42)\n\nclassifier.fit(x_train_df, y_train_df)\n\ny_valid_pred = classifier.predict(x_valid_df)\n\nprint(\"accuracy_score: \",metrics.accuracy_score(y_valid_df, y_valid_pred))\n\ny_test_pred = classifier.predict(x_test_df)\n\n# %% [markdown]\n# # CSV Creation\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:09:15.388474Z\",\"iopub.execute_input\":\"2023-09-24T10:09:15.388791Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.396769Z\",\"shell.execute_reply.started\":\"2023-09-24T10:09:15.388766Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.395692Z\"}}\noutput_df=pd.DataFrame(columns=[\"ID\",\"label_1\",\"label_2\",\"label_3\",\"label_4\"])\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:09:15.398475Z\",\"iopub.execute_input\":\"2023-09-24T10:09:15.398805Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.416751Z\",\"shell.execute_reply.started\":\"2023-09-24T10:09:15.398775Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.415229Z\"}}\nIDs = list(i for i in range(1, len(test_df)+1))\noutput_df[\"ID\"] = IDs\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:09:15.418479Z\",\"iopub.execute_input\":\"2023-09-24T10:09:15.418764Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.432027Z\",\"shell.execute_reply.started\":\"2023-09-24T10:09:15.418744Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.430116Z\"}}\noutput_df[\"label_1\"] = y_test_predict_after_pca\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:09:15.433876Z\",\"iopub.execute_input\":\"2023-09-24T10:09:15.434259Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.456704Z\",\"shell.execute_reply.started\":\"2023-09-24T10:09:15.434229Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.455472Z\"}}\noutput_df\n\n# %% [code] {\"execution\":{\"iopub.status.busy\":\"2023-09-24T10:09:15.457638Z\",\"iopub.execute_input\":\"2023-09-24T10:09:15.457990Z\",\"iopub.status.idle\":\"2023-09-24T10:09:15.477584Z\",\"shell.execute_reply.started\":\"2023-09-24T10:09:15.457961Z\",\"shell.execute_reply\":\"2023-09-24T10:09:15.476275Z\"}}\noutput_df.to_csv('/kaggle/working/output12_3.csv',index=False)", "metadata": {"_uuid": "e419ac52-2915-4e2b-be9e-2ef25da5d8f7", "_cell_guid": "5c64204d-adc4-456f-baea-224b31846263", "collapsed": false, "jupyter": {"outputs_hidden": false}, "trusted": true}, "execution_count": null, "outputs": []}]}
